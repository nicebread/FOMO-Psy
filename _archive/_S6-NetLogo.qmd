---
title: Session 6 - NetLogo implementation of Buri
number-sections: true
description: Try to implement your Buri model in Netlogo
---

# Overview

| Topic                                            | Duration | Notes                  |
| ------------------------------------------------ | -------- | ---------------------- |
| **Workshop**: Netlogo implementation             | 180      | See instructions below |
| **[Homework]**: Prepare for first theory session | -        |                        |

: {.striped}


# Netlogo: Buri implementation

## First implementation: A single donkey

1. Download `FOMO-homework/Buridans_Ass/NetLogo-Framework/Buri_environment.nlogo`. This contains all global variables and the environment. It also has the stump of your donkey's behavioral program
2. Implement your own model - start with a single donkey.
     - Code together in the group - but every participant should write the code on their own local machine. Add your own name to the file name to distinguish different implementations. Save the `nlogo` files in the folder of your donkey.
     - Group members can agree on a single implementation. But they can also have different irrelevant choices (such as the shape of the donkey), or even differing implementations (in case that the theoretical model was underspecified).
3. Document the gaps: In an extra document in the repository (called `arbitrary_decision.md`), document all implementation decisions that were *not* determined by the formal model (i.e., which were arbitrary)
4. For the first run: *A priori* choose sensible starting values for your free model parameters.
     - If group members do not converge on a single setting, they can use different starting values.
5. Record the simulation result in Table 1 of `FOMO-homework/Buridans_Ass/NetLogo-Framework/Results.md`
      - How many ticks does the donkey survive with these parameters?
      - If your model is not deterministic, for example because you have some random numbers in it, record at least 10 runs with the same parameter setting and record the average survival time.

::: {.callout-note}
# Be careful when pushing changes to the remote repository

You jointly edit the results file. You probably will encounter merge conflicts; resolve them with care! Do not (inadvertently) delete the results of the other group.
:::

## Model optimization: Free parameters

- Manually adjust the free parameters - you are allowed and encouraged to play around. Try to find a better setting (i.e., a parameter setting where the donkey survives longer)
- Record the new parameter settings and the new results in Table 1 of `FOMO-homework/Buridans_Ass/NetLogo-Framework/Results.md` (set `Run` to 2, 3, ... etc.)

**Optimizing free parameters is not a change of the model structure (or theory) itself!**
Nearly all models contain free parameters that may be optimized to fit the model to empirical reality.

## (optional) Model optimization: Model structure

It can happen that the donkey acts strangely, in a non-adaptive way.
In this case, first search for bugs in the implementation.

However, it could also be that the theoretical model itself is erroneous (or suboptimal), in the sense that it does not solve the task. Often, problems with the model's structure itself are realized during implementation.

**In this case, you can revise the theoretical model.** Change the model description in the `dev` branch and implement the changes. When you are happy with the revised model, increase the version number in the `cff` file, push the revised model to the `main` branch and create a new release.

## (optional) Many donkeys: Parameter optimization

In NetLogo, it is very easy to create many agents of the same kind. Instead of manually optimizing the free parameters, you can use algorithms, such as an **evolutionary algorithm**, to find the best parameter settings.

::: {.callout-note}
Always keep in mind: Evolution needs (a) variation (usually induced by mutation or recombination) and (b) selection.
:::

Many optimization algorithms are possible; here are some suggestions (with increasing complexity). 

### Who survives the longest?
1. Create many Donkeys with varying settings of their parameters (i.e. in the `setup` function for the donkeys). Some possibilities for creating variation:
   1. "[Random search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Random_search)": Set parameters randomly within the allowed parameter range.
   2. "[Grid search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search)": Create systematic combinations all parameters.
2. Run the simulation, see which donkeys survive the longest.

### Evolutionary algorithm

1. Create many Donkeys with varying settings of their parameters (see above)
2. After some time let the worst-performing die (i.e., those who are dead anyway, or have the lowest health value) → **Selection**
3. Of those which survive, create offspring which has some random variation of their (single) parent (i.e., take the parameter settings of the surviving donkey, add some random noise to the settings, and create offspring with the updates settings) → **Mutation/Variation**

NetLogo has many built-in functions for these evolutionary steps; for example:

- `setxy random-xcor random-ycor`: Let agents start at a random position
- `hatch` is a primitive that creates a provided number of identical copies of a turtle (i.e., the offspring). It allows optional rules defined for the new turtles by following it with brackets [] (see [help page](https://ccl.northwestern.edu/netlogo/bind/primitive/hatch.html)).
- `max-n-of` and `min-n-of`: Select the `n` agents with the highest or lowest value in a property (see [help file](https://ccl.northwestern.edu/netlogo/bind/primitive/max-n-of.html)). Here's some pseudo-code, selecting the 10 buris with the highest and lowest value in `health`:

```default
; reproduction: the 10 fittest buris reproduce (2 kids)
ask max-n-of 10 buris [health] [

  ; save the value of property1 of the parent in a variable
  let prev_property1 property1

  ; create 2 offsprings with random variation
  hatch 2 [
    lt 45  ; turn away
    fd 1   ; walk away from parent to make it visible

    ; add random variation to property1 of the offspring
    set property1 prev_property1 - 0.025 + random-float 0.05
    output-print (word "Old property1: " prev_property1 "; new property1: " property1)
  ]
]

; death: the 10 unfittest buris die
ask min-n-of 10 buris [health] [
    die
]
```

Monitor the distribution of parameter settings in the population of donkeys: Across evolving generations, it (often) will converge to the optimal values.

::: {.callout-note}
Except for an *exhaustive search* that enumerates all possible combinations of the entire parameter space, there's no guarantee that optimization algorithms converge to the (globally) optimal solution. For example, they can get stuck in local optima. In this case, larger mutations in an evolutionary algorithm are helpful, because they allow to "jump" out of the local minimum/maximum and to find a better solution.

![](http://turingfinance.com/wp-content/uploads/2015/07/Multimodal-Fitness-Landscape.png)

(Image from [http://turingfinance.com](http://turingfinance.com))
:::

# Homework (individual)

Read the chapter for the Imagined Contact Hypothesis: Section 2.3 and 2.4 (p. 133 - 137), plus the section on moderating conditions (p. 153 – 164).